# app.py â€” 7 about ... (Embedding classifier + Whitelist replies + Simple counter endings + Robust fixes + Summary page)
import os, json, re
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import numpy as np
import streamlit as st

# ===== Optional Embedding (for emotion classification) =====
# í•­ìƒ ê¸°ë³¸ê°’ì„ ë¨¼ì € ì¡ì•„ NameError ë°©ì§€
# ê¶Œì¥ ê¸°ë³¸: Day1Kim/Qwen3-Embedding-0.6B-Korean (HF)
EMBED_MODEL_NAME = os.environ.get(
    "EMBED_MODEL_NAME",
    "Day1Kim/Qwen3-Embedding-0.6B-Korean"
)
try:
    from sentence_transformers import SentenceTransformer
    # Qwen3 ê¸°ë°˜ ST: trust_remote_code í•„ìš”
    _embed_model = SentenceTransformer(
        EMBED_MODEL_NAME,
        trust_remote_code=True
    )
    # í•„ìš”ì‹œ ì…ë ¥ ê¸¸ì´ ì œí•œ(ì•ˆì •ì„±/ì†ë„)
    _max_len = int(os.environ.get("EMBED_MAX_TOKENS", "512"))
    if hasattr(_embed_model, "max_seq_length"):
        _embed_model.max_seq_length = _max_len
except Exception as _e:
    _embed_model = None  # ì„ë² ë”© ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ í´ë°±

# ===== (ì„ íƒ) EEVE ì˜µì…˜ =====
USE_EEVE_SELECTOR = os.environ.get("USE_EEVE_SELECTOR", "0") == "1"   # ì¸ë±ìŠ¤ë§Œ ì„ íƒ
USE_EEVE_SIMILAR  = os.environ.get("USE_EEVE_SIMILAR",  "0") == "1"   # ìœ ì‚¬ë¬¸ì¥ â†’ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ìŠ¤ëƒ…
OLLAMA_URL = os.environ.get("OLLAMA_URL", "http://127.0.0.1:11434/api/chat")
EEVE_MODEL = os.environ.get("EEVE_MODEL", "eeve-korean-10_8b")

_http = None
if USE_EEVE_SELECTOR or USE_EEVE_SIMILAR:
    import requests
    _http = requests.Session()
    _http.trust_env = False

def _ensure_http():
    """ìš”ì•½ ë‹¨ê³„ì—ì„œ EEVE ì˜µì…˜ì´ êº¼ì ¸ ìˆì–´ë„ LLMì„ ì“°ê¸° ìœ„í•´ ì„¸ì…˜ í™•ë³´."""
    global _http
    if _http is None:
        try:
            import requests
            _http = requests.Session()
            _http.trust_env = False
        except Exception:
            _http = None
    return _http

def _eeve_chat(payload: dict, timeout: int = 15) -> str:
    sess = _ensure_http()
    if sess is None:
        raise RuntimeError("LLM ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨")
    r = sess.post(OLLAMA_URL, json=payload, timeout=timeout)
    r.raise_for_status()
    data = r.json()
    return (data.get("message", {}) or {}).get("content", "").strip()

def _eeve_choose_index(n: int, emo_key: str, timeout: int = 10) -> int:
    system = (
        "ë„ˆëŠ” ë°°ì—´ì—ì„œ ì¸ë±ìŠ¤ í•˜ë‚˜ë§Œ ê³ ë¥´ëŠ” ë„ìš°ë¯¸ì•¼.\n"
        "- ì˜¤ì§ JSON í•œ ì¤„ë§Œ ì¶œë ¥: {\"idx\":ì •ìˆ˜}\n"
        "- ì¶”ê°€ í…ìŠ¤íŠ¸/ì„¤ëª…/ê°œí–‰/ë”°ì˜´í‘œ/ì½”ë“œë¸”ëŸ­ ê¸ˆì§€"
    )
    user = (
        f"ë°°ì—´ ê¸¸ì´: {n}\n"
        f"í—ˆìš© ì¸ë±ìŠ¤: 0..{n-1}\n"
        f"ìƒí™©(ê°ì •): {emo_key}\n"
        "ì§€ê¸ˆ ìƒí™©ì— ê°€ì¥ ì–´ìš¸ë¦¬ëŠ” ì¸ë±ìŠ¤ í•˜ë‚˜ë¥¼ ê³¨ë¼."
    )
    payload = {
        "model": EEVE_MODEL,
        "messages": [
            {"role": "system", "content": system},
            {"role": "user",   "content": user},
        ],
        "options": {"temperature": 0, "num_predict": 16, "stop": ["\n", "â€", "\""]},
        "stream": False,
    }
    text = _eeve_chat(payload, timeout=timeout)
    m = re.search(r'\{\s*"idx"\s*:\s*(-?\d+)\s*\}', text)
    if not m:
        raise ValueError("LLM-Selector: JSON idx not found")
    k = int(m.group(1))
    if not (0 <= k < n):
        raise ValueError(f"LLM-Selector: idx out of range ({k})")
    return k

def _eeve_suggest_similar(emo_key: str, items: List[str], timeout: int = 10) -> List[str]:
    n = min(len(items), 8)
    guide = " / ".join(items[:n])
    system = (
        "ë„ˆëŠ” ì˜ˆì‹œ ë¬¸ì¥ì„ ì ˆëŒ€ ë²—ì–´ë‚˜ì§€ ì•Šê³  ë¹„ìŠ·í•œ í˜•íƒœë¡œë§Œ ì œì•ˆí•˜ëŠ” ë„ìš°ë¯¸ì•¼.\n"
        "- 30ì ì´ë‚´, ë°˜ë§, ì´ëª¨ì§€/ì™¸êµ­ì–´/ìš•ì„¤/ì¡´ëŒ“ë§ ê¸ˆì§€\n"
        "- ì˜ˆì‹œì˜ ì–´íœ˜/ë¦¬ë“¬/í†¤ì„ ìœ ì§€í•˜ë˜ ì˜ë¯¸ë¥¼ ì‚´ì§ë§Œ ë³€í˜•\n"
        "- ì¶œë ¥ì€ JSON ë°°ì—´ í•œ ì¤„: [\"ë¬¸ì¥1\",\"ë¬¸ì¥2\",\"ë¬¸ì¥3\"]\n"
        "- ì¶”ê°€ ì„¤ëª…/ê°œí–‰/ì½”ë“œë¸”ëŸ­ ê¸ˆì§€"
    )
    user = f"ê°ì •: {emo_key}\nì˜ˆì‹œ(ì°¸ê³ ): {guide}\në¹„ìŠ·í•œ ë¬¸ì¥ 3ê°œë§Œ."
    payload = {
        "model": EEVE_MODEL,
        "messages": [
            {"role": "system", "content": system},
            {"role": "user",   "content": user},
        ],
        "options": {"temperature": 0.2, "num_predict": 80, "stop": ["\n"]},
        "stream": False,
    }
    text = _eeve_chat(payload, timeout=timeout)
    try:
        arr = json.loads(text)
        if isinstance(arr, list):
            return [str(x) for x in arr][:3]
    except Exception:
        pass
    return []

# ===== Emotion keys & anchors =====
EMO_KEYS = ["hope","trust","sadness","solitude","anger"]

# ë©€í‹° ì•µì»¤(í‰ê·  ì„ë² ë”©) â€” ì§§ì€ ì¸ì‚¬/ê¸ì •í¸í–¥ ë³´ì •
EMO_ANCHOR_LISTS = {
    "hope":     ["í¬ë§ì„ ì£¼ëŠ” ë”°ëœ»í•œ ë§", "ìœ„ë¡œì™€ ê²©ë ¤ê°€ ë‹´ê¸´ ë§", "ì•ì„ ë³´ê²Œ í•´ì£¼ëŠ” ë§"],
    "trust":    ["ë¯¿ìŒê³¼ ì•ˆì‹¬ì„ ì£¼ëŠ” ë§", "ì˜ì§€í•˜ê³  ê¸°ëŒ€ê²Œ í•˜ëŠ” ë§", "í•¨ê»˜í•˜ìëŠ” ì•½ì†ì˜ ë§"],
    "sadness":  ["ìŠ¬í””ì„ ë“œëŸ¬ë‚´ëŠ” ë§", "ê°€ìŠ´ì´ ì €ë¦° ì•„í”ˆ ë§", "ëˆˆë¬¼ì´ ë§ºíˆëŠ” ì„œëŸ¬ìš´ ë§"],
    "solitude": ["ì™¸ë¡œì›€ê³¼ ê³ ë…ì„ ë“œëŸ¬ë‚´ëŠ” ë§", "í™€ë¡œ ë‚¨ê²¨ì§„ ë“¯í•œ ë§", "ë¹„ì–´ ìˆëŠ” ë§ˆìŒì˜ ë§"],
    "anger":    ["ë¶„ë…¸ì™€ ì§œì¦ì„ ë“œëŸ¬ë‚´ëŠ” ë§", "ìƒì²˜ ì£¼ëŠ” ê±°ì¹œ ë§", "ë¶ˆí¸í•¨ì„ ê°•í•˜ê²Œ í† ë¡œí•˜ëŠ” ë§"],
}

# ===== Whitelist-only Eebi replies (<=30 chars, casual, safe) =====
EEBI_WHITELIST: Dict[str, List[str]] = {
    "hope": [
        "ê·¸ ë§ì„ ë“¤ìœ¼ë‹ˆ ê¸°ìš´ì´ ë‚˜.",
        "ì¢‹ì€ ì´ì•¼ê¸° í•´ì¤˜ì„œ ê³ ë§ˆì›Œ.",
        "ë„ˆëŠ” ì°¸ ì¹œì ˆí•˜êµ¬ë‚˜.",
        "ì¡°ê¸ˆì€ ë²„í‹¸ ìˆ˜ ìˆê² ì–´.",
        "ë”°ëœ»í•œ ë§ˆìŒì´ ëŠê»´ì ¸.",
    ],
    "trust": [
        "ë„ˆë¥¼ ì¢€ ë” ë¯¿ì–´ë³¼ê²Œ.",
        "ë„¤ê°€ ê³ì— ìˆì–´ ë‹¤í–‰ì´ì•¼.",
        "ì¡°ê¸ˆ ì•ˆì‹¬ì´ ë¼.",
        "ë„¤ ë§ì´ë©´ ë”°ë¼ê°€ë³¼ê²Œ.",
        "ì˜¤ëŠ˜ì€ ê¸°ëŒˆê²Œ.",
    ],
    "sadness": [
        "ë§ˆìŒì´ ìê¾¸ ê°€ë¼ì•‰ì•„.",
        "ì™œ ì´ë¦¬ ë¬´ê±°ìš´ì§€ ëª¨ë¥´ê² ì–´.",
        "ê·¸ëƒ¥â€¦ ìš¸ê³  ì‹¶ì–´.",
        "ìˆ¨ì´ ìê¾¸ ì–•ì•„ì ¸.",
        "ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´.",
    ],
    "solitude": [
        "ì—¬ê¸´ ì—¬ì „íˆ ì¡°ìš©í•´.",
        "ë„ˆ ë– ë‚˜ë©´ ë” ë¹„ì–´ë²„ë ¤.",
        "ë°¤ì´ ê¸¸ê²Œ ëŠ˜ì–´ì¡Œì–´.",
        "í˜¼ìì„  ì¢€ ì–´ë ¤ì›Œ.",
        "ë©”ì•„ë¦¬ë§Œ ë‚¨ì•„ìˆì–´.",
    ],
    "anger": [
        "ì¡°ê¸ˆ ë¶ˆí¸í–ˆì–´.",
        "ê·¸ë§Œí–ˆìœ¼ë©´ ì¢‹ê² ì–´.",
        "ì†ì´ ê½‰ ë§‰íˆëŠ” ëŠë‚Œì´ì•¼.",
        "ë§ì´ ë„ˆë¬´ ê±°ì¹ ì—ˆì–´.",
        "ìƒì²˜ê°€ ì•„ì§ ë”°ê°€ì›Œ.",
    ],
}

# ìš”ì•½ì ë¬¸êµ¬
EMO_LABEL_KO = {
    "hope":     "í¬ë§ì„ ì£¼ëŠ”",
    "trust":    "ì‹ ë¢°ë¥¼ ë†’ì´ëŠ”",
    "sadness":  "ìŠ¬í””ì„ ë“œëŸ¬ë‚´ëŠ”",
    "solitude": "ì™¸ë¡œì›€ì„ ìê·¹í•˜ëŠ”",
    "anger":    "ë¶„ë…¸ë¥¼ ìœ ë°œí•˜ëŠ”",
}

# ===== Endings =====
EMO_ENDINGS = {
    "hope":     ("ì—”ë”©: ì¹œêµ¬", "ì´ë¹„ëŠ” ì¹œêµ¬ë“¤ì—ê²Œ ê±¸ì–´ê°”ë‹¤."),
    "trust":    ("ì—”ë”©: ì˜ì§€", "ì´ë¹„ëŠ” ì´ì œ ì™¸ë¡­ì§€ ì•Šì•˜ë‹¤."),
    "sadness":  ("ì—”ë”©: ëˆˆë¬¼", "ì´ë¹„ëŠ” ê³ ê°œë¥¼ í‘¹ ìˆ™ì˜€ë‹¤."),
    "solitude": ("ì—”ë”©: ê³ ë…", "ì´ë¹„ëŠ” ì“¸ì“¸í•¨ì— íŒŒë¬»í˜”ë‹¤."),
    "anger":    ("ì—”ë”©: ë°œí†±", "ì´ë¹„ëŠ” ë°œí†±ì„ ë“œëŸ¬ëƒˆë‹¤."),
}

# ===== Policy / Text utils =====
_PROFANITY_RE    = re.compile(r"(ì”¨ë°œ|ã……ã…‚|ì¢†|ë³‘ì‹ |ê°œìƒˆ|ë‹¥ì³|êº¼ì ¸|ì£½ì–´|íŒ¨ë²„|ìì‚´|ë…„|ë†ˆ|í‹€ë”±|ê¹€ì¹˜ë…€|í•œë‚¨|í‘í˜•|~ì¶©)", re.IGNORECASE)
_HAS_ASCII_ALPHA = re.compile(r"[A-Za-z]")
_HAS_EMOJI       = re.compile(r"[\U00010000-\U0010FFFF]")
_POLITE_ENDINGS  = re.compile(r"(ìš”[.!?]?$|ì…ë‹ˆë‹¤$|ì‹­ì‹œì˜¤$|ì„¸ìš”$|í•´ìš”$)")
_GREETING_RE     = re.compile(r"(ì•ˆë…•|ë°˜ê°€ì›Œ|ì–´ì„œì™€|ê³ ë§ˆì›Œ|ë°˜ê°‘|í™˜ì˜|ì¢‹ì•„|ê¸°ë»)", re.IGNORECASE)

def normalize_text(s: str) -> str:
    s = s.replace("...", "â€¦")
    s = re.sub(r"\s+", " ", s).strip()
    return s

def violates_policy(s: str) -> bool:
    if not s: return True
    if s == "â€¦": return False
    if _HAS_ASCII_ALPHA.search(s): return True
    if _HAS_EMOJI.search(s): return True
    if _PROFANITY_RE.search(s): return True
    if _POLITE_ENDINGS.search(s): return True
    if len(s) > 30: return True
    return False

def validate_eebi_text(s: str, max_chars: int = 30) -> bool:
    s = normalize_text(s)
    if len(s) == 0: return False
    if len(s) > max_chars: return False
    if _HAS_ASCII_ALPHA.search(s): return False
    if _HAS_EMOJI.search(s): return False
    if _PROFANITY_RE.search(s): return False
    if _POLITE_ENDINGS.search(s): return False
    return True

def split_utterance_ko(s: str, max_chars: int = 30) -> list:
    s = normalize_text(s)
    out, i, n = [], 0, len(s)
    while i < n:
        if n - i <= max_chars:
            out.append(s[i:]); break
        chunk = s[i:i+max_chars]
        best = -1
        for m in re.finditer(r"[.?!â€¦]", chunk): best = max(best, m.end())
        for m in re.finditer(r"[â€â€™)\]]", chunk): best = max(best, m.end())
        if best == -1:
            space = chunk.rfind(" ")
            best = space + 1 if space != -1 else max_chars
        piece = chunk[:best].rstrip()
        out.append(piece)
        i += best
        while i < n and s[i] == " ": i += 1
    return out

def char_stream(text: str):
    for ch in text:
        yield ch

# Streamlit ë²„ì „ í˜¸í™˜: write_stream ì—†ìœ¼ë©´ st.writeë¡œ í´ë°±
def write_reply(text: str):
    if hasattr(st, "write_stream"):
        return st.write_stream(char_stream(text))
    return st.write(text)

# ===== Similarity helpers =====
# ===== Anchor mean cache (Qwen3 ì „ìš© ì•„ë‹˜, ê³µìš©) =====
_ANCHOR_CACHE = None  # (keys, A) where A shape = (len(EMO_KEYS), dim), L2-normalized

def _get_anchor_means():
    """ê°ì •ë³„ ì•µì»¤(ì—¬ëŸ¬ ë¬¸ì¥)ì˜ í‰ê·  ë²¡í„°ë¥¼ 1íšŒë§Œ ê³„ì‚°í•´ì„œ ìºì‹œ."""
    global _ANCHOR_CACHE
    if _ANCHOR_CACHE is not None:
        return _ANCHOR_CACHE
    if _embed_model is None:
        return None
    keys = list(EMO_ANCHOR_LISTS.keys())
    mats = []
    for k in keys:
        vecs = np.asarray(_embed_model.encode(EMO_ANCHOR_LISTS[k]))
        v = vecs.mean(axis=0)
        v = v / (np.linalg.norm(v) + 1e-12)
        mats.append(v)
    A = np.asarray(mats)  # (len(keys), dim)
    _ANCHOR_CACHE = (keys, A)
    return _ANCHOR_CACHE

def _norm(x: np.ndarray) -> np.ndarray:
    n = np.linalg.norm(x, axis=-1, keepdims=True) + 1e-12
    return x / n

def _levenshtein(a: str, b: str) -> int:
    la, lb = len(a), len(b)
    dp = list(range(lb+1))
    for i in range(1, la+1):
        prev, dp[0] = dp[0], i
        for j in range(1, lb+1):
            cur = dp[j]
            cost = 0 if a[i-1] == b[j-1] else 1
            dp[j] = min(dp[j]+1, dp[j-1]+1, prev+cost)
            prev = cur
    return dp[lb]

def _closest_whitelist(line: str, items: List[str], embed_vec: Optional[np.ndarray]) -> str:
    best, best_sim = None, -1.0
    if _embed_model is not None and embed_vec is not None:
        cand_vecs = _embed_model.encode(items)
        cand_vecs = np.asarray([v/(np.linalg.norm(v)+1e-12) for v in cand_vecs])
        sim = (cand_vecs @ embed_vec).reshape(-1)
        idx = int(np.argmax(sim))
        best, best_sim = items[idx], float(sim[idx])
    best_ed, best_ed_line = 10**9, None
    for s in items:
        d = _levenshtein(line, s)
        if d < best_ed:
            best_ed, best_ed_line = d, s
    return best if best is not None else best_ed_line

# ===== Embedding classifier (ë©€í‹° ì•µì»¤ í‰ê·  + ì¸ì‚¬ ê°€ë“œë ˆì¼) =====
def classify_top_emotion(text: str) -> Tuple[str, float]:
    if _embed_model is None or not text:
        t = text.lower()
        scores = {
            "hope":     int(("í¬ë§" in t) or ("ê´œì°®" in t) or ("ê³ ë§ˆ" in t) or ("ì‘ì›" in t) or bool(_GREETING_RE.search(text))),
            "trust":    int(("ë¯¿" in t) or ("ì•ˆì‹¬" in t) or ("ê´œì°®ì„" in t)),
            "sadness":  int(("ìŠ¬í””" in t) or ("ìš¸" in t) or ("ì•„íŒŒ" in t) or ("í˜ë“¤" in t)),
            "solitude": int(("ì™¸ë¡­" in t) or ("í˜¼ì" in t) or ("ê³ ë…" in t) or ("í—ˆì „" in t)),
            "anger":    int(("í™”" in t) or ("ì§œì¦" in t) or ("ë¯¸ì›Œ" in t) or ("ì‹«" in t)),
        }
        key = max(scores, key=scores.get)
        return key, float(scores[key])

    # ì¸ì‚¬/í™˜ì˜ë¥˜ëŠ” hopeë¡œ ìŠ¤ëƒ…
    if _GREETING_RE.search(text):
        return "hope", 0.99

    u = _embed_model.encode([text])[0]
    got = _get_anchor_means()
    if got is None:
        return "solitude", 0.0
    A_keys, A_vecs = got

    u = _norm(np.asarray(u))
    A = _norm(np.asarray(A_vecs))
    sims = (A @ u).reshape(-1)
    idx = int(np.argmax(sims))
    st.session_state.last_sims = {k: float(s) for k, s in zip(A_keys, sims)}  # ë””ë²„ê·¸
    return A_keys[idx], float(sims[idx])

# ===== Simple counter engine =====
def update_emotion_count(ss, key: str):
    """ì„ íƒëœ ê°ì • í•˜ë‚˜ë§Œ +1 ëˆ„ì  (0ì—ì„œ ì‹œì‘, ìµœëŒ€ 7)."""
    ss.emotions_total[key] = float(ss.emotions_total.get(key, 0.0)) + 1.0
    ss.emo_hist.append(key)

# ===== Summary helpers (NEW) =====
def _pick_final_ending(ss) -> str:
    """7í„´ ì¢…ë£Œ í›„ ìµœì¢… ì—”ë”© ê°ì • ê²°ì • (ë™ì  ì‹œ 'ê°€ì¥ ìµœê·¼ì— ì„ íƒëœ ê°ì •' ìš°ì„ )."""
    totals = ss.emotions_total
    max_v = max(totals.values()) if totals else 0.0
    cands = [k for k, v in totals.items() if v == max_v]
    # ìµœê·¼ ë“±ì¥ ê°ì • ìš°ì„ 
    for ek in reversed(ss.emo_hist):
        if ek in cands:
            return ek
    # ê·¸ë˜ë„ ì—†ìœ¼ë©´ ê³ ì • ìš°ì„ ìˆœìœ„
    for ek in EMO_KEYS:
        if ek in cands:
            return ek
    return "solitude"

def _dominant_emotion(ss) -> str:
    """ìš”ì•½ í”„ë¡¬í”„íŠ¸/í´ë°±ì—ì„œë„ ì“°ëŠ” ìš°ì„¸ ê°ì •(ë™ì ì‹œ ìµœê·¼ ë“±ì¥ ìš°ì„ )."""
    return _pick_final_ending(ss)

def _build_summary_prompt(ss) -> Tuple[str, str]:
    """ê°œì„ ì•ˆ ë°˜ì˜ System/User í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ê° ë¬¸ì¥ ìµœëŒ€ 30ì, ì´ 3ë¬¸ì¥)."""
    # System
    system = (
        "ë„ˆëŠ” ì§€ê¸ˆ 'ìˆ²ì†ì˜ ê³° ì´ë¹„' ì—­í• ì´ì•¼.\n"
        "ì•„ë˜ 7ê°œì˜ ì‚¬ìš©ì ì…ë ¥ê³¼ ê°ì • ì¹´ìš´í„°ë¥¼ ë³´ê³ \n"
        "ì‚¬ìš©ìê°€ ì–´ë–¤ ê°ì •ì˜ ì´ì•¼ê¸°ë¥¼ ê°€ì¥ ë§ì´ í–ˆëŠ”ì§€, ê·¸ë¦¬ê³  ì–´ë–¤ ë¶„ìœ„ê¸°ì˜ ëŒ€í™”ë¥¼ ë‚˜ëˆ´ëŠ”ì§€\n"
        "3ê°œì˜ ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ ì¤˜.\n\n"
        "í•„ìˆ˜ ê·œì¹™:\n"
        "- ê° ë¬¸ì¥ì€ ìµœëŒ€ 30ì ì´ë‚´ë¡œ ì¶œë ¥ (ì´ 3ë¬¸ì¥)\n"
        "- í•œêµ­ì–´, ë¬¸ì¥ í˜•íƒœ(ë²ˆí˜¸/ë¶ˆë¦¿/ë”°ì˜´í‘œ/ì´ëª¨ì§€ ê¸ˆì§€)\n"
        "- ê±´ê°•Â·ì •ì¹˜Â·ì‹¬ë¦¬Â·ì¢…êµÂ·ê°œì¸ ì‹ ë… ë“± ë¯¼ê° ì¶”ë¡  ê¸ˆì§€\n"
        "- ê°ì • ì¹´ìš´í„° ìˆ˜ì¹˜ë¥¼ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ë§ê³ , 'ì£¼ë¡œ ~í•œ í†¤'ì²˜ëŸ¼ ì„œìˆ \n"
        "- 1ë²ˆì§¸ ë¬¸ì¥: \"ë„ˆëŠ” ~ ê°ì •ì´ ëŠê»´ì§ˆ ì´ì•¼ê¸°ë¥¼ ë§ì´ í–ˆêµ¬ë‚˜\" í˜•íƒœ\n"
        "- 2ë²ˆì§¸ ë¬¸ì¥: ê·¸ëŸ° ì´ì•¼ê¸°ë¥¼ ìì£¼ ë“¤ì€ ì´ë¹„ê°€ ì–´ë–»ê²Œ ëŠë¼ëŠ”ì§€\n"
        "- 3ë²ˆì§¸ ë¬¸ì¥: ì´ë¹„ ì…ì¥ì—ì„œ ë“¤ì—ˆë˜ ê°ì •ì— ëŒ€í•œ ìƒê°/ë§(ë°˜ë§)\n"
        "- ë™ì ì´ë©´ ìµœê·¼ì— ë“±ì¥í•œ ê°ì •ì„ ê¸°ë°˜ìœ¼ë¡œ ì„œìˆ \n"
        "- ì¶œë ¥ì€ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ:\n\n"
        "1) ì²« ë¬¸ì¥\n2) ë‘ ë²ˆì§¸ ë¬¸ì¥\n3) ì„¸ ë²ˆì§¸ ë¬¸ì¥"
    )
    # User
    ulist = ss.user_hist[:7] + [""] * (7 - len(ss.user_hist))
    counters = ss.emotions_total
    user = (
        "[ëŒ€í™” ì…ë ¥ 7ê°œ]\n"
        f"1) {ulist[0]}\n"
        f"2) {ulist[1]}\n"
        f"3) {ulist[2]}\n"
        f"4) {ulist[3]}\n"
        f"5) {ulist[4]}\n"
        f"6) {ulist[5]}\n"
        f"7) {ulist[6]}\n\n"
        "[ê°ì • ì¹´ìš´í„° í•©ê³„(0~7)]\n"
        f'{json.dumps({k:int(counters.get(k,0)) for k in EMO_KEYS}, ensure_ascii=False)}\n\n'
        "ìš”ì²­:\n- ìœ„ ë‚´ìš©ì„ ë°˜ì˜í•´ 3ë¬¸ì¥ìœ¼ë¡œë§Œ, í˜•ì‹ì— ë§ì¶° ì¶œë ¥í•˜ì„¸ìš”."
    )
    return system, user

def _llm_summary(ss, timeout=15) -> List[str]:
    """LLMì„ í˜¸ì¶œí•´ 3ë¬¸ì¥ì„ ë°›ë˜, ì‹¤íŒ¨/í˜•ì‹ë¶ˆì¼ì¹˜ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
    system, user = _build_summary_prompt(ss)
    payload = {
        "model": EEVE_MODEL,
        "messages": [
            {"role":"system","content": system},
            {"role":"user",  "content": user},
        ],
        "options": {"temperature": 0.2, "num_predict": 180, "stop": []},
        "stream": False,
    }
    text = _eeve_chat(payload, timeout=timeout)
    # ê¸°ëŒ€ í˜•ì‹: "1) ...\n2) ...\n3) ..."
    lines = []
    for m in re.finditer(r'(?:^|\n)\s*\d\)\s*(.+)', text):
        s = normalize_text(m.group(1))
        if len(s) > 30:
            s = split_utterance_ko(s, 30)[0]
        lines.append(s)
    # ê¸¸ì´/ê²€ì¦
    out = []
    for s in lines[:3]:
        # ì´ë¹„ ë§í’ì„  ê·œì¹™(ë°˜ë§/30ì/ì˜ë¬¸X/ì´ëª¨ì§€X/ìš•ì„¤X/ì¡´ëŒ“ë§X)
        # ìš”ì•½ ë¬¸ì¥ì€ 'ì´ë¹„' í™”ìì´ë¯€ë¡œ validate_eebi_textë¡œ ë™ì¼ ê²€ì¦
        if validate_eebi_text(s, 30):
            out.append(s)
        else:
            # ê³¼í•œ ì œì•½ìœ¼ë¡œ ë§‰íˆë©´ ìµœëŒ€í•œ ì •ëˆ
            s = normalize_text(s)
            s = s[:30]
            if not s: s = "â€¦"
            out.append(s)
    return out if len(out) == 3 else []

def _fallback_summary(ss) -> List[str]:
    """LLM ì‹¤íŒ¨ ì‹œ ê·œì¹™ ê¸°ë°˜ 3ë¬¸ì¥ ìƒì„±(ê° 30ì ì´ë‚´, ë°˜ë§)."""
    dom = _dominant_emotion(ss)
    emo_word = {
        "hope":"í¬ë§",
        "trust":"ì‹ ë¢°",
        "sadness":"ìŠ¬í””",
        "solitude":"ì™¸ë¡œì›€",
        "anger":"ë¶„ë…¸",
    }.get(dom, "ê°ì •")
    l1 = f"ë„ˆëŠ” {emo_word}ì´ ëŠê»´ì§ˆ ì´ì•¼ê¸°ë¥¼ ë§ì´ í–ˆêµ¬ë‚˜"
    # 30ì ì»·
    l1 = split_utterance_ko(l1, 30)[0]
    feel = {
        "hope":"ë‚´ ë§ˆìŒì´ ì¡°ê¸ˆ ë”°ëœ»í•´ì¡Œì–´.",
        "trust":"ì¡°ê¸ˆ ë” ê¸°ëŒ€ê³  ì‹¶ì–´ì¡Œì–´.",
        "sadness":"ë‚´ ìˆ¨ì´ ì‚´ì§ ë¬´ê±°ì›Œì¡Œì–´.",
        "solitude":"ìˆ²ì´ ë” ì¡°ìš©í•´ì§„ ê²ƒ ê°™ì•„.",
        "anger":"ê°€ìŠ´ì´ ì¡°ê¸ˆ ë‹µë‹µí•´ì¡Œì–´.",
    }.get(dom, "ë‚´ ë§ˆìŒì´ ì¡°ê¸ˆ í”ë“¤ë ¸ì–´.")
    l2 = split_utterance_ko(feel, 30)[0]
    think = {
        "hope":"ë‹¤ìŒì—” ë„ˆì˜ ë¹›ì„ ë” ë“¤ë ¤ì¤˜.",
        "trust":"ì˜¤ëŠ˜ì€ ë„¤ ì˜†ì— ë” ì„œ ìˆì„ê²Œ.",
        "sadness":"ì¡°ê¸ˆ ì‰¬ì–´ê°€ë„ ê´œì°®ì•„.",
        "solitude":"ë‚˜ëŠ” ì—¬ê¸°ì„œ ê¸°ë‹¤ë¦´ê²Œ.",
        "anger":"ì¡°ê¸ˆë§Œ ì²œì²œíˆ ë§í•´ì¤˜.",
    }.get(dom, "ë‚˜ëŠ” ë„¤ ê³ì—ì„œ ë“¤ì„ê²Œ.")
    l3 = split_utterance_ko(think, 30)[0]
    # validate
    out = []
    for s in [l1,l2,l3]:
        s = normalize_text(s)
        if len(s) > 30: s = split_utterance_ko(s, 30)[0]
        if not validate_eebi_text(s, 30):
            s = "â€¦"
        out.append(s)
    return out

# ===== Assets & UI =====
ASSETS_DIR = Path(__file__).parent / "assets"
MAIN_IMG = ASSETS_DIR / "main_scene.png"

st.set_page_config(page_title="7 about ...", page_icon="ğŸ§¸", layout="centered")

# ê³µí†µ ìŠ¤íƒ€ì¼
st.markdown("""
<style>
.block-container { max-width: 980px; margin: 0 auto; }
div.stTextArea textarea { height: 48px !important; resize: none; overflow: hidden; }
h1.app-title { text-align: center; font-size: clamp(56px, 8vw, 120px) !important;
  font-weight: 800; line-height: 1.1; margin-top: 40px; margin-bottom: 18px; }
div.stButton > button{ font-size: 30px; font-weight: 700; border: 3px solid #DADDE1;
  box-sizing: border-box; width: 260px; height: 48px; padding: 0 22px;
  border-radius: 14px; display: block; margin: 12px auto; }
@keyframes fadeUp { 0% { opacity: 0; transform: translateY(6px);} 100% { opacity: 1; transform: translateY(0);} }
.prologue-line{ opacity: 0; text-align: center; font-size: 22px; line-height: 1.7;
  margin: 6px 0; animation: fadeUp .8s ease forwards; }
.prologue-wrap{ margin-top: 48px; margin-bottom: 24px; }
.prologue-cta { opacity: 0; animation: fadeUp .8s ease forwards; }
.scene-wrap { display:flex; flex-direction:column; align-items:center; gap:18px; }
.bubble {
  width: 100% !important;         /* â† í¼ê³¼ ë™ì¼ í­ */
  max-width: none !important;      /* â† ìƒí•œ í•´ì œ */
  border: 2px solid #DADDE1;
  border-radius: 18px;
  padding: 14px 18px;
  background: #fff;
  box-sizing: border-box;
}
.bubble-eebi{ border-color:#cfd6dd; }
.bubble-narr{ border-style:dashed; color:#6b7280; }
.bubble .label{ font-weight:700; color:#374151; margin-right:8px; }
</style>
""", unsafe_allow_html=True)

st.markdown("""
<style>
/* ë²„íŠ¼ ì „í­/ì¤‘ì•™ ê°•ì œ í•´ì œ: ê°€ë¡œ ì •ë ¬(ì»¬ëŸ¼ ë°°ì¹˜) ìœ„í•´ í­ ìë™ */
div.stButton > button{
  font-size: 30px;
  font-weight: 700;
  border: 3px solid #DADDE1;
  box-sizing: border-box;
  width: auto !important;          /* â† ì „í­ í•´ì œ */
  height: 48px;
  padding: 0 22px;
  border-radius: 14px;
  display: inline-block;            /* â† ê°€ë¡œë¡œ ìì—°ìŠ¤ëŸ½ê²Œ */
  margin: 12px 0 !important;        /* ì¢Œìš° ë§ˆì§„ì€ ì»¬ëŸ¼ì´ ë‹´ë‹¹ */
}

/* (ì„ íƒ) ë„ˆë¬´ ê³¼í•œ ì „ì—­ ì¤‘ì•™ ì •ë ¬ì€ ìœ ì§€í•´ë„ ë˜ì§€ë§Œ,
   ë²„íŠ¼ ë°°ì¹˜ëŠ” ì»¬ëŸ¼ìœ¼ë¡œ ì œì–´í•˜ë¯€ë¡œ ì´ ì •ë„ë§Œ ë‘ë©´ ì¶©ë¶„í•©ë‹ˆë‹¤. */
</style>
""", unsafe_allow_html=True)

st.markdown("""
<style>
/* === (ì¶”ê°€) ì „ì—­ ì¤‘ì•™ ì •ë ¬ === */
.block-container { text-align: center; }  /* markdown ê¸°ë³¸ í…ìŠ¤íŠ¸ */
div[data-testid="stMarkdown"] { text-align: center; } /* st.write/markdown ì¶œë ¥ */
div.stTextArea textarea { text-align: center !important; } /* ì…ë ¥ì°½ ë‚´ë¶€ í…ìŠ¤íŠ¸ */
.bubble { text-align: center; } /* ë§í’ì„  ë‚´ë¶€ */
.bubble .label { display: block; margin-bottom: 6px; } /* ë¼ë²¨ì„ í•œ ì¤„ ìœ„ë¡œ */
.prologue-line { text-align: center; } /* í”„ë¡¤ë¡œê·¸ ë¬¸êµ¬ (ì´ë¯¸ ì¤‘ì•™ì´ì§€ë§Œ ì•ˆì „ì°¨ì› ì¬ëª…ì‹œ) */

/* metric(ì—”ë”© í˜ì´ì§€) ìˆ«ìì™€ ë¼ë²¨ ì¤‘ì•™ ì •ë ¬ */
[data-testid="stMetric"] div { justify-content: center !important; }
[data-testid="stMetricValue"], [data-testid="stMetricLabel"] { text-align: center !important; }

/* ëª©ë¡/ë¬¸ë‹¨/í—¤ë”ë„ ì¤‘ì•™(ë§ˆí¬ë‹¤ìš´ ì „ì—­) */
div[data-testid="stMarkdown"] h1, 
div[data-testid="stMarkdown"] h2, 
div[data-testid="stMarkdown"] h3,
div[data-testid="stMarkdown"] p, 
div[data-testid="stMarkdown"] li { 
  text-align: center; 
}
</style>
""", unsafe_allow_html=True)

st.markdown("""
<style>
/* ìš”ì•½ì ë§í’ì„ ì˜ ë¼ë²¨(ğŸ“œ ìš”ì•½ì)ë§Œ ìˆ¨ê¹€ */
.bubble-narr .label{ display:none !important; }
</style>
""", unsafe_allow_html=True)

st.markdown("""
<style>
/* 1) ì´ë¯¸ì§€ ì»¨í…Œì´ë„ˆë¥¼ 50%ë¡œ ì¤„ì´ê³  ì¤‘ì•™ ì •ë ¬ */
.scene-wrap [data-testid="stImage"]{
  width: 50% !important;
  max-width: min(320px, 45vw) !important;  /* ì ˆë°˜ ìƒí•œ */
  margin: 0 auto !important;               /* ì¤‘ì•™ ì •ë ¬ */
}

/* 2) ì»¨í…Œì´ë„ˆ ì•ˆì˜ imgëŠ” ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤ */
.scene-wrap [data-testid="stImage"] img{
  width: 100% !important;
  height: auto !important;
  display: block !important;
  border-radius: 12px;
}
</style>
""", unsafe_allow_html=True)

# ===== State =====
def ensure_main_state():
    ss = st.session_state
    if "page" not in ss: ss.page = "title"
    if "turn" not in ss: ss.turn = 1
    if "eebi_text" not in ss: ss.eebi_text = "â€¦ì•ˆë…•? ë‚œ ì´ë¹„ì•¼."
    if "narr_text" not in ss: ss.narr_text = ""
    if "silent_turns" not in ss: ss.silent_turns = 0
    # íŒŒë¼ë¯¸í„°(ê°ì •) ëˆ„ì ì¹˜: 0ì—ì„œ ì‹œì‘
    if "emotions_total" not in ss: ss.emotions_total = {k: 0.0 for k in EMO_KEYS}
    if "user_hist" not in ss: ss.user_hist = []
    if "eebi_hist" not in ss: ss.eebi_hist = []
    if "emo_hist" not in ss: ss.emo_hist = []           # ê° í„´ì—ì„œ ì„ íƒëœ ê°ì • ê¸°ë¡
    if "wl_idx" not in ss: ss.wl_idx = {k: 0 for k in EMO_KEYS}
    # Summary ìƒíƒœ
    if "summary_lines" not in ss: ss.summary_lines = None  # List[str] | None
    if "summary_step" not in ss: ss.summary_step = 0        # 0..3

def title_page():
    st.markdown("<h1 class='app-title'>7 about ...</h1>", unsafe_allow_html=True)

    # ë ˆì´ì•„ì›ƒì€ ê·¸ëŒ€ë¡œ ìœ ì§€: [spacer, (ê¸°ì¡´ start ìë¦¬), (ê¸°ì¡´ ending ìë¦¬)]
    c_sp, c1, c2 = st.columns([6, 1, 1])

    # ê¸°ì¡´ start ë²„íŠ¼ì€ ì œê±°í•˜ê³ , ê¸°ì¡´ ending ìœ„ì¹˜(c2)ì— 'ì‹œì‘' ë²„íŠ¼ë§Œ ë°°ì¹˜
    with c2:
        start = st.button("ì‹œì‘", key="btn_start", use_container_width=True)

    st.markdown("---")

    if start:
        st.session_state.page = "prologue"
        st.rerun()

def prologue_page():
    lines = [
        "ë‹¹ì‹ ì€ ìˆ² ì†ì— í™€ë¡œ ìˆëŠ” ê³°ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.",
        "ê³°ì—ê²Œ ë§ì„ ê±¸ì–´ ì´ì•¼ê¸°ë¥¼ í•´ë³´ì„¸ìš”",
        "ëŒ€í™”ëŠ” ì´ 7ë²ˆ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "ì´ì•¼ê¸°ì— ë”°ë¼ ê³°ì˜ ê°ì •ì´ ë³€í™”í•©ë‹ˆë‹¤.",
        "7í„´ í›„ ìµœì¢… ê°ì • ìƒíƒœì— ë”°ë¼ ì—”ë”©ì´ ë³€í™”í•©ë‹ˆë‹¤.",
    ]
    st.write("")
    st.markdown("<div class='prologue-wrap'>", unsafe_allow_html=True)
    base_delay, step = 0.2, 1.0
    for i, t in enumerate(lines):
        delay = base_delay + i*step
        st.markdown(f"<p class='prologue-line' style='animation-delay:{delay:.2f}s'>{t}</p>", unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)
    final_delay = base_delay + len(lines)*step + 0.2
    st.markdown(
        f"<div class='prologue-cta' style='animation-delay:{final_delay:.2f}s'>",
        unsafe_allow_html=True,
    )

    # â–¶ ì˜¤ë¥¸ìª½ ì •ë ¬: spacer + ë²„íŠ¼ ì»¬ëŸ¼
    c_sp, c_btn = st.columns([6, 1])
    with c_btn:
        ok = st.button("ì•Œê² ì–´ìš”!", key="btn_ok_prologue", use_container_width=True)

    st.markdown("</div>", unsafe_allow_html=True)

    if ok:
        st.session_state.page = "main"; st.rerun()

def pick_whitelist_line(ss, emo_key: str) -> str:
    items = EEBI_WHITELIST.get(emo_key, ["â€¦"])
    n = len(items)
    if n == 0: return "â€¦"

    # 1) í•˜ì´ë¸Œë¦¬ë“œ-ìŠ¤ëƒ…
    if USE_EEVE_SIMILAR and _ensure_http() is not None and _embed_model is not None:
        try:
            cand_list = _eeve_suggest_similar(emo_key, items)
            if cand_list:
                TAU_COS, MAX_EDIT = 0.92, 6
                kept = []
                for c in cand_list:
                    c = normalize_text(c)
                    if not validate_eebi_text(c): continue
                    c_vec = _embed_model.encode([c])[0]
                    c_vec = c_vec / (np.linalg.norm(c_vec)+1e-12)
                    wl_vecs = _embed_model.encode(items)
                    wl_vecs = np.asarray([v/(np.linalg.norm(v)+1e-12) for v in wl_vecs])
                    cos_max = float((wl_vecs @ c_vec).max())
                    ed_min = min(_levenshtein(c, s) for s in items)
                    if (cos_max >= TAU_COS) or (ed_min <= MAX_EDIT):
                        kept.append((c, c_vec))
                if kept:
                    c, c_vec = kept[0]
                    snapped = _closest_whitelist(c, items, c_vec)
                    snapped = normalize_text(snapped)
                    return snapped if validate_eebi_text(snapped) else normalize_text(items[0])
        except Exception:
            pass

    # 2) LLM-Selector (ì¸ë±ìŠ¤ë§Œ)
    if USE_EEVE_SELECTOR and _ensure_http() is not None:
        try:
            k = _eeve_choose_index(n, emo_key)
            line = normalize_text(items[k])
            if validate_eebi_text(line): return line
        except Exception:
            pass

    # 3) ë¼ìš´ë“œë¡œë¹ˆ
    k = ss.wl_idx.get(emo_key, 0) % n
    ss.wl_idx[emo_key] = k + 1
    line = normalize_text(items[k])
    if not validate_eebi_text(line):
        for cand in items:
            c = normalize_text(cand)
            if validate_eebi_text(c): return c
        return "â€¦"
    return line

def main_page():
    ensure_main_state()
    ss = st.session_state
    st.markdown("<div class='scene-wrap'>", unsafe_allow_html=True)

    # (A) ì”¬ ì´ë¯¸ì§€ â€” ìµœìƒë‹¨
    if MAIN_IMG.exists():
        st.image(str(MAIN_IMG))  # use_container_width / width íŒŒë¼ë¯¸í„° ìƒëµ
    else:
        st.info("ì”¬ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”. assets/main_scene.png íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        st.markdown(
            "<div style='width:min(720px,92vw);height:420px;border:2px dashed #DADDE1;"
            "border-radius:18px;display:flex;align-items:center;justify-content:center;color:#94a3b8;'>"
            "[ scene placeholder ]</div>",
            unsafe_allow_html=True
        )

    # (B) í•´ì„¤ì ë§í’ì„  â€” ë‚´ìš©ì´ ìˆì„ ë•Œë§Œ, ì´ë¹„ ë°”ë¡œ ìœ„ì— í‘œì‹œ
    if ss.narr_text:
        st.markdown(
            f"<div class='bubble bubble-narr'><span class='label'>ğŸ“œ ìš”ì•½ì</span>{ss.narr_text}</div>",
            unsafe_allow_html=True
        )

    # (C) ì´ë¹„ ë§í’ì„  â€” ì‚¬ìš©ì ì…ë ¥ ë°”ë¡œ ìœ„
    st.markdown(
        f"<div class='bubble bubble-eebi'><span class='label'>ğŸ» ì´ë¹„</span>{ss.eebi_text}</div>",
        unsafe_allow_html=True
    )

    with st.form("user_say", clear_on_submit=True):
        user_text = st.text_area(
            label="",
            key=f"user_text_{ss.turn}",
            max_chars=30, height=48,
            placeholder="ë‹¹ì‹ ì˜ ë§ì„ 30ì ì´ë‚´ë¡œ ì ì–´ì£¼ì„¸ìš”",
            label_visibility="collapsed"
        )
        # ì…ë ¥ì°½ ê·¸ëŒ€ë¡œ, ì œì¶œ ë²„íŠ¼ë§Œ ìš°ì¸¡ ì •ë ¬
        col_sp, col_btn = st.columns([6, 1])
        with col_btn:
            submitted = st.form_submit_button("ë§í•˜ê¸°", use_container_width=True)

    if submitted:
        txt = (user_text or "").strip()
        if txt == "" or txt in ["â€¦", ".", "..."]:
            ss.silent_turns += 1
            ss.narr_text = "ë‹¹ì‹ ì€ ì´ë¹„ì—ê²Œ ì•„ë¬´ ë§ë„ ê±´ë„¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            ss.eebi_text = "â€¦"
        elif violates_policy(txt):
            ss.silent_turns += 1
            ss.narr_text = "ì…ë ¥ì´ ì •ì±…ì— ë§ì§€ ì•ŠìŠµë‹ˆë‹¤."
            ss.eebi_text = "â€¦"
        else:
            try:
                # 1) ê°ì • ë¶„ë¥˜ (ìµœìƒìœ„ 1ê°œ)
                emo_key, sim = classify_top_emotion(txt)
                if emo_key not in EMO_KEYS:
                    emo_key, sim = "solitude", 0.5

                # 2) ì¹´ìš´í„° ë°©ì‹: ì„ íƒ ê°ì • +1
                update_emotion_count(ss, emo_key)

                # 3) ì´ë¹„ ëŒ€ì‚¬ â€” í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜
                first = pick_whitelist_line(ss, emo_key)
                if len(first) > 30:
                    first = split_utterance_ko(first, 30)[0]
                write_reply(first)
                ss.eebi_text = first

                # 4) íˆìŠ¤í† ë¦¬/ìš”ì•½
                ss.user_hist.append(txt)
                ss.eebi_hist.append(first)
                label = EMO_LABEL_KO.get(emo_key, "ì–´ë–¤ ê°ì •ë„")
                ss.narr_text = f"ë‹¹ì‹ ì€ {label} ì´ì•¼ê¸°ë¥¼ í–ˆìŠµë‹ˆë‹¤."
            except Exception as e:
                ss.narr_text = "ì´ë¹„ëŠ” ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                ss.eebi_text = "â€¦"
                st.error(f"ì„ë² ë”©/ë¶„ë¥˜ ì—ëŸ¬: {e}")

        ss.turn += 1
        if ss.turn > 7:
            # â˜… ë³€ê²½: resultê°€ ì•„ë‹ˆë¼ summaryë¡œ ì´ë™
            ss.page = "summary"
        st.rerun()

    st.markdown(f"<div style='color:#6b7280'>í˜„ì¬ í„´: <b>{ss.turn}</b> / 7</div>", unsafe_allow_html=True)
    # if "last_sims" in ss:
    #     st.caption(f"ë””ë²„ê·¸ - ìœ ì‚¬ë„: {ss.last_sims}")
    st.markdown("</div>", unsafe_allow_html=True)

# ===== Summary Page (NEW) =====
def summary_page():
    ensure_main_state()
    ss = st.session_state
    st.markdown("<div class='scene-wrap'>", unsafe_allow_html=True)

    # ì”¬ ì´ë¯¸ì§€ (ì„ íƒì ìœ¼ë¡œ ë™ì¼ ë Œë”)
    if MAIN_IMG.exists():
        st.image(str(MAIN_IMG))
    else:
        st.markdown(
            "<div style='width:min(720px,92vw);height:240px;border:2px dashed #DADDE1;"
            "border-radius:18px;display:flex;align-items:center;justify-content:center;color:#94a3b8;'>"
            "[ scene placeholder ]</div>",
            unsafe_allow_html=True
        )

    # ìµœì´ˆ ì§„ì… ì‹œ ìš”ì•½ë¬¸ ìƒì„±(LLM â†’ í´ë°±)
    if ss.summary_lines is None:
        lines = []
        try:
            lines = _llm_summary(ss, timeout=20)
        except Exception:
            lines = []
        if len(lines) != 3:
            lines = _fallback_summary(ss)
        ss.summary_lines = lines
        ss.summary_step = 0

    # í˜„ì¬ ë‹¨ê³„ì— ë”°ë¼ ë¬¸ì¥ í‘œì‹œ
    shown = ss.summary_step
    for i in range(shown):
        st.markdown(
            f"<div class='bubble bubble-eebi'><span class='label'>ğŸ» ì´ë¹„</span>{ss.summary_lines[i]}</div>",
            unsafe_allow_html=True
        )

    # ì»¨íŠ¸ë¡¤ ë²„íŠ¼: ë‹µë³€ / ì—”ë”© ë³´ê¸°
    c_sp, c_btn = st.columns([6, 1])
    with c_btn:
        if ss.summary_step < 3:
            if st.button("ë‹¤ìŒ", key=f"btn_summary_next_{ss.summary_step}", use_container_width=True):
                ss.summary_step += 1
                st.rerun()
        else:
            if st.button("ì—”ë”© ë³´ê¸°", key="btn_go_result", use_container_width=True):
                ss.page = "result"
                st.rerun()

    st.markdown("</div>", unsafe_allow_html=True)

def result_page():
    ss = st.session_state
    st.success("ëŒ€í™”ê°€ ëë‚¬ì–´ìš”. ì´ë¹„ì˜ ìµœì¢… ê°ì • ìƒíƒœì…ë‹ˆë‹¤.")
    cols = st.columns(5)
    for i, k in enumerate(EMO_KEYS):
        cols[i].metric(k, f"{int(ss.emotions_total[k])} / 7")

    # ìµœì¢… ì—”ë”© ê²°ì •
    final_key = _pick_final_ending(ss)
    title, desc = EMO_ENDINGS.get(final_key, ("ì—”ë”©: ë¯¸ì •", "ì•„ì§ ì •í•´ì§€ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."))
    st.write("---")
    st.subheader(title)
    st.write(desc)

    st.write("---")
    st.write("ëŒ€í™” ìš”ì•½:")
    for i, (u,e) in enumerate(zip(ss.user_hist, ss.eebi_hist), start=1):
        st.write(f"{i}. ë‹¹ì‹ : {u}")
        st.write(f"   ì´ë¹„: {e}")

    c_sp, c_btn = st.columns([6, 1])
    with c_btn:
        back = st.button("ì²˜ìŒìœ¼ë¡œ", use_container_width=True)
    
    if back:
        keep = []
        for k in list(st.session_state.keys()):
            if k not in keep:
                del st.session_state[k]
        st.session_state.page = "title"
        st.rerun()

# ===== Router =====
def ensure_main_state_wrapper():
    ensure_main_state()
    # if _embed_model is None:
    #     st.warning("ì„ë² ë”© ëª¨ë¸ì´ ì—†ì–´ í‚¤ì›Œë“œ ë¶„ë¥˜ê¸°ë¡œ ë™ì‘í•©ë‹ˆë‹¤. ì •í™•ë„ë¥¼ ë†’ì´ë ¤ë©´ 'pip install sentence-transformers' í›„ ì¬ì‹¤í–‰í•˜ì„¸ìš”.", icon="âš ï¸")
    # if USE_EEVE_SIMILAR:
    #     st.info("í•˜ì´ë¸Œë¦¬ë“œ-ìŠ¤ëƒ… í™œì„±í™”: ìœ ì‚¬ í›„ë³´ ì œì•ˆ í›„ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ë¡œ ìŠ¤ëƒ…í•©ë‹ˆë‹¤.", icon="ğŸ§²")
    # if USE_EEVE_SELECTOR:
    #     st.info("LLM-Selector í™œì„±í™”: í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì¸ë±ìŠ¤ë§Œ ì„ íƒí•©ë‹ˆë‹¤.", icon="ğŸ§©")
    # if not USE_EEVE_SELECTOR and not USE_EEVE_SIMILAR:
    #     st.caption("LLM ì˜µì…˜ ë¹„í™œì„±í™”: í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ë¼ìš´ë“œë¡œë¹ˆ ëª¨ë“œ.")

ensure_main_state_wrapper()
if st.session_state.page == "title":
    title_page()
elif st.session_state.page == "prologue":
    prologue_page()
elif st.session_state.page == "summary":   # â˜… ìƒˆ ê²½ë¡œ
    summary_page()
elif st.session_state.page == "result":
    result_page()
else:
    main_page()
